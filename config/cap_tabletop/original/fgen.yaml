type: fgen
max_tokens: 512
temperature: 0
query_prefix: "\n# define function: "
query_suffix: "."
stop:
  - "# define"
  - "# example"
llm:
  type: ChatOpenAI
  model_name: gpt-3.5-turbo-0301
  max_tokens: 512
  temperature: 0
maintain_session: false
include_context: true
api:
  include_all: True